CSV File Names:

model2.1_100_test.csv
model2.1_600_test.csv
model2.1_23-77_test.csv
model2.1_200_RarePlane_test.csv
model2.1_100_RarePlane_real_test.csv

During the testing phase, the Convolutional Neural Network model named "model2.1_1920x1080.h5" processed an input folder 
containing a mix of real and synthetic images. Its task was to separate these images into two distinct folders. Real 
images were placed in the "real" folder, while synthetic images were assigned to the "synthetic" folder. This classification 
process was repeated for each image in the input folder until all images were classified.

Upon completion of the execution, the model not only sorted the input images into their respective predicted folders
but also generated a CSV file. This file contains the image names along with the labels assigned by the model.

For further details regarding the data and outputs, please refer to the following bulleted points.

* File name: model2.1_100_test.csv
  Observations: The model successfully classified a total of 100 images, consisting of 50 real images from the WASABI 
  dataset and 50 synthetic images generated by a computer. During testing, the model achieved a remarkable 100% accuracy, 
  accurately assigning all images to their respective folders.

* File name: model2.1_600_test.csv
  Observations: The model accomplished the classification of 600 images, with 300 being real images sourced from the 
  WASABI dataset, and the remaining 300 being synthetic images generated by a computer. The accuracy of the model during 
  testing was 100%, indicating that it correctly classified all the images into their respective folders.

* File name: model2.1_23-77_test.csv
  Observations: The model effectively classified a set of 100 images, comprising 23 real images from the WASABI dataset 
  and 77 synthetic images generated by a computer. Impressively, the model achieved a 100% accuracy rate during testing, 
  correctly categorizing all images into their appropriate folders. This particular test aimed to evaluate the model's 
  performance when faced with an imbalanced distribution of corresponding images.

* File name: model2.1_200_RarePlane_test.csv
  Observations: In this particular test, the model encountered a completely new dataset. Originally trained on images from 
  the WASABI dataset and computer-generated images by the AFRL team, the model faced a novel challenge of working with previously 
  unseen data. To assess its adaptability, we utilized the Rare Plane dataset, which consisted of real and synthetic images depicting 
  various airport runways. During this test, the model was presented with 200 images, evenly split between 100 real and 100 synthetic 
  images. However, the model's performance fell short, accurately predicting only 50% of the given images. Surprisingly, it misclassified 
  all 200 images as synthetic, indicating a struggle to differentiate between real and synthetic instances.

* File name: model2.1_100_RarePlane_real_test.csv
  Observations: Based on the results obtained from the previous test run (model2.1_200_RarePlane_test.csv), it is evident that the 
  current model encountered challenges in accurately distinguishing between real and synthetic files. In light of these findings, 
  a subsequent test was conducted with a specific focus: providing the model with the same set of 100 real images used in the 
  'model2.1_200_RarePlane_test' run. Unfortunately, the model exhibited a strikingly low accuracy of 0%, mistakenly classifying all 
  100 real images as synthetic. Several factors could contribute to these erroneous predictions. Firstly, the model was initially 
  trained using images of a fixed size, specifically 1920x1080 pixels. However, many real images from the Rare Plane dataset are 
  either twice the dimensions or considerably larger. As the model resizes these images to match its input size (1920x1080), a 
  significant loss of crucial feature information may occur. To pinpoint the exact cause behind the incorrect image classifications, 
  further testing is necessary. One approach could involve conducting additional test runs to ascertain whether the observed loss of 
  features during image resizing is indeed contributing to the model's inaccuracies. Alternatively, retraining the model with a more 
  diverse dataset could also be considered, enabling it to extract a wider range of features during the training phase.
  
