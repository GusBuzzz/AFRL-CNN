The model below is responsible for accurately classifying real or synthetic images.

Model's evaluation: loss: 0.6932 - binary_accuracy: 0.5500

Model's saved file name: 'model_1920x1080.h5'

Model's architecture:

model = keras.Sequential([
    # Block One
    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=[1080, 1920, 3]),
    layers.MaxPool2D(),

    # Block Two
    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),
    layers.MaxPool2D(),

    # Block Three
    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),
    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),
    layers.MaxPool2D(),

    # Head
    layers.Flatten(),
    layers.Dense(6, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1, activation='sigmoid'),
])

model.compile(
    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001),
    loss='binary_crossentropy',
    metrics=['binary_accuracy'],
)

Epochs = 15
Batch size = 16

Observations: Increasing the epochs to 15 and changing the learning rate to 0.001 resulted in a 17.5% accuracy increase.

Ways to improve: change the architecture of the model and the dense size.

UPDATE:
Retained the model since I realized that the data sets were miss labeled.

The same model that is shown above now has a new accuracy of (loss: 0.6944 - binary_accuracy: 0.4500)
